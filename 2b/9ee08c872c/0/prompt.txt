Implement the following plan:

# Plan: Build `examples/entire_session_search/` (CocoIndex v1)

## Context

Building a CocoIndex v1 example that indexes [Entire](https://entire.dev) checkpoint data (AI coding session transcripts, prompts, context summaries) into Postgres with pgvector for semantic search. This is for a blog post / partnership pitch showing how CocoIndex + Entire work together.

The example follows the patterns established by `examples/text_embedding/` (Postgres target, SentenceTransformer embeddings, pgvector queries) and `examples/multi_codebase_summarization/` (hierarchical directory walking, LLM processing, `mount_each`).

Entire stores session data on git branch `entire/checkpoints/v1` in this layout:
```
<shard(2char)>/<checkpoint_id(10char)>/<session_idx>/
  ├── metadata.json     # token counts, files touched, timestamps
  ├── full.jsonl        # conversation transcript (one JSON object per line)
  ├── prompt.txt        # user's initial prompt
  ├── context.md        # AI-generated session summary
  └── content_hash.txt  # content fingerprint
```

---

## Files to create

### 1. `examples/entire_session_search/main.py`

The main flow file. Structure:

```
Config section:
  - DATABASE_URL, TABLE_EMBEDDINGS, TABLE_METADATA, PG_SCHEMA_NAME from env
  - PG_DB context key
  - _embedder = SentenceTransformerEmbedder("sentence-transformers/all-MiniLM-L6-v2")
  - _splitter = RecursiveSplitter()

Dataclasses:
  - SessionEmbeddingRow: id (int), checkpoint_id (str), session_index (str),
    content_type (str), role (str), text (str), embedding (Annotated[NDArray, _embedder])
  - SessionMetadataRow: checkpoint_id (str), session_index (str),
    prompt_summary (str), total_tokens (int), files_touched (str as JSON),
    agent_percentage (float | None)

Lifespan:
  - @coco_aio.lifespan → create_pool, register_db, provide PG_DB

Functions:
  - parse_transcript(content: str) -> list[TranscriptChunk]
    Parses full.jsonl, extracts text from each turn, skips trivial entries.
    @coco.function (no memo — cheap operation)

  - extract_session_info(filename: str) -> SessionInfo
    Extracts checkpoint_id and session_index from file path.
    Plain function (not coco.function — pure string parsing)

  - process_checkpoint(file: FileLike, emb_table, meta_table) -> None
    @coco.function(memo=True) — the main per-file processor.
    Reads file content, determines file type by name:
      - full.jsonl: parse_transcript → embed each chunk → declare_row
      - prompt.txt: embed directly → declare_row
      - context.md: RecursiveSplitter → embed each chunk → declare_row
      - metadata.json: parse JSON → declare_row on meta_table
    Uses IdGenerator for stable chunk IDs.

  - app_main(checkpoints_dir: pathlib.Path) -> None
    @coco.function — mounts both table targets, walks dir, mount_each.

App:
  - app = coco_aio.App(AppConfig(name="EntireSessionSearch"), app_main, ...)

Query demo:
  - query_once(pool, query_text) → pgvector cosine search on session_embeddings
  - Interactive REPL loop at __main__
```

Key decisions:
- **One `mount_each` over all files** (not per-checkpoint grouping). `walk_dir` with `recursive=True` and patterns like `**/*.jsonl`, `**/*.txt`, `**/*.md`, `**/*.json` walks all session files. Each file becomes its own component via `mount_each`. Simpler than nested mounting per checkpoint — CocoIndex handles the component path keying automatically.
- Actually, reconsider: we need to handle 4 different file types. Two approaches:
  - **Option A**: Single `walk_dir` with broad patterns, dispatch by filename in `process_checkpoint`. Simpler code, one `mount_each`.
  - **Option B**: Four separate `walk_dir` calls (one per file type), four `mount_each` calls. Cleaner type separation but more boilerplate.
  - Going with **Option A** — matches how `multi_codebase_summarization` handles heterogeneous processing in one function.
- **Postgres over Qdrant** — consistent with other v1 examples, fewer dependencies (Postgres is already required for CocoIndex internal state).

### 2. `examples/entire_session_search/models.py`

Pydantic/dataclass models. Keeping it separate like `multi_codebase_summarization/models.py`:

```python
@dataclass
class TranscriptChunk:
    role: str
    text: str

@dataclass
class SessionInfo:
    checkpoint_id: str
    session_index: str
```

### 3. `examples/entire_session_search/pyproject.toml`

```toml
[project]
name = "entire-session-search-v1"
version = "0.1.0"
description = "Semantic search over AI coding sessions captured by Entire."
requires-python = ">=3.11"
dependencies = [
    "cocoindex[postgres,sentence_transformers]>=1.0.0a10",
    "asyncpg>=0.29.0",
    "pgvector>=0.4.1",
    "numpy",
    "python-dotenv>=1.0.1",
]
```

### 4. `examples/entire_session_search/README.md`

Structure (matching the tone/format of `multi_codebase_summarization/README.md` but shorter):

- Title + one-liner
- What it does (3 bullet points)
- Why incremental matters (one paragraph)
- Prerequisites (Postgres, Entire with some sessions)
- Setup (git worktree add, pip install, env vars)
- Run (cocoindex update, python main.py query)
- Configuration table (env vars)
- How it works (mermaid diagram of the flow)

No badge spam. Concise. Match user's writing style — direct, not corporate.

---

## Implementation order

1. Create `models.py` (simple, no dependencies)
2. Create `main.py` (the core flow)
3. Create `pyproject.toml`
4. Create `README.md`

---

## Key v1 API calls used

| What | API | Source |
|------|-----|--------|
| Walk files | `localfs.walk_dir(path, recursive=True, path_matcher=...)` | `connectors/localfs.py` |
| File access | `file.read_text()`, `file.read()`, `file.file_path.path` | `resources/file.py` |
| Mount per-file | `coco_aio.mount_each(fn, files.items(), *args)` | `asyncio.py` |
| Concurrent subtasks | `coco_aio.map(fn, items, *args)` | `asyncio.py` |
| Postgres table | `target_db.mount_table_target(name, schema, pg_schema_name)` | `connectors/postgres` |
| Schema from class | `postgres.TableSchema.from_class(MyRow, primary_key=[...])` | `connectors/postgres` |
| Declare row | `table.declare_row(row=MyRow(...))` | `connectors/postgres` |
| Chunk text | `_splitter.split(text, chunk_size, chunk_overlap, language)` | `ops/text.py` |
| Embed text | `await _embedder.embed(text)` | `ops/sentence_transformers.py` |
| Stable IDs | `IdGenerator()` → `await id_gen.next_id(dep)` | `resources/id.py` |
| Context | `coco.ContextKey[T]()`, `builder.provide()`, `coco.use_context()` | core API |
| Vector column | `Annotated[NDArray, _embedder]` | type annotation convention |

---

## Verification

1. `pip install -e .` in the example dir
2. `git worktree add entire_checkpoints entire/checkpoints/v1` (needs an Entire-enabled repo)
3. Set `POSTGRES_URL` env var
4. `cocoindex update main.py` — should process checkpoint files
5. `python main.py query "what session fixed the auth bug"` — should return ranked results
6. Run `cocoindex update main.py` again — should show 0 changes (all memoized)


If you need specific details from before exiting plan mode (like exact code snippets, error messages, or content you generated), read the full transcript at: /Users/sriharithyagarajan/.REDACTED.jsonl

---

Ok, I tried the @examples/entire_session_search/README.md instructions, I'm getting htis error now: cocoindex update main.py

Traceback (most recent call last):
  File "/Users/sriharithyagarajan/Documents/GitHub-Projects/cocoindex/.venv/bin/cocoindex", line 10, in <module>
    sys.exit(cli())
             ^^^^^
  File "/Users/sriharithyagarajan/Documents/GitHub-Projects/cocoindex/.venv/lib/python3.11/site-packages/click/core.py", line 1485, in __call__
    return self.main(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/sriharithyagarajan/Documents/GitHub-Projects/cocoindex/.venv/lib/python3.11/site-packages/click/core.py", line 1406, in main
    rv = self.invoke(ctx)
         ^^^^^^^^^^^^^^^^
  File "/Users/sriharithyagarajan/Documents/GitHub-Projects/cocoindex/.venv/lib/python3.11/site-packages/click/core.py", line 1873, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/sriharithyagarajan/Documents/GitHub-Projects/cocoindex/.venv/lib/python3.11/site-packages/click/core.py", line 1269, in invoke
    return ctx.invoke(self.callback, **ctx.params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/sriharithyagarajan/Documents/GitHub-Projects/cocoindex/.venv/lib/python3.11/site-packages/click/core.py", line 824, in invoke
    return callback(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/sriharithyagarajan/Documents/GitHub-Projects/cocoindex/python/cocoindex/cli.py", line 596, in update
    asyncio.run_coroutine_threadsafe(_do(), env_loop).result()
  File "/Users/sriharithyagarajan/.local/share/uv/python/cpython-3.11.14-macos-aarch64-none/lib/python3.11/concurrent/futures/_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/sriharithyagarajan/.local/share/uv/python/cpython-3.11.14-macos-aarch64-none/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/Users/sriharithyagarajan/Documents/GitHub-Projects/cocoindex/python/cocoindex/cli.py", line 569, in _do
    env = await app._environment._get_env()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/sriharithyagarajan/Documents/GitHub-Projects/cocoindex/python/cocoindex/_internal/environment.py", line 345, in _get_env
    await anext(async_gen)
  File "/Users/sriharithyagarajan/Documents/GitHub-Projects/cocoindex/examples/entire_session_search/main.py", line 65, in coco_lifespan
    async with await postgres.create_pool(DATABASE_URL) as pool:
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/sriharithyagarajan/Documents/GitHub-Projects/cocoindex/python/cocoindex/connectors/postgres/_target.py", line 1112, in create_pool
    return await asyncpg.create_pool(dsn, init=_init_with_pgvector, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/sriharithyagarajan/Documents/GitHub-Projects/cocoindex/.venv/lib/python3.11/site-packages/asyncpg/pool.py", line 439, in _async__init__
    await self._initialize()
  File "/Users/sriharithyagarajan/Documents/GitHub-Projects/cocoindex/.venv/lib/python3.11/site-packages/asyncpg/pool.py", line 466, in _initialize
    await first_ch.connect()
  File "/Users/sriharithyagarajan/Documents/GitHub-Projects/cocoindex/.venv/lib/python3.11/site-packages/asyncpg/pool.py", line 153, in connect
    self._con = await self._pool._get_new_connection()
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/sriharithyagarajan/Documents/GitHub-Projects/cocoindex/.venv/lib/python3.11/site-packages/asyncpg/pool.py", line 573, in _get_new_connection
    raise ex
  File "/Users/sriharithyagarajan/Documents/GitHub-Projects/cocoindex/.venv/lib/python3.11/site-packages/asyncpg/pool.py", line 560, in _get_new_connection
    await self._init(con)
  File "/Users/sriharithyagarajan/Documents/GitHub-Projects/cocoindex/python/cocoindex/connectors/postgres/_target.py", line 1106, in _init_with_pgvector
    await pgvector.asyncpg.register_vector(conn)
  File "/Users/sriharithyagarajan/Documents/GitHub-Projects/cocoindex/.venv/lib/python3.11/site-packages/pgvector/asyncpg/register.py", line 5, in register_vector
    await conn.set_type_codec(
  File "/Users/sriharithyagarajan/Documents/GitHub-Projects/cocoindex/.venv/lib/python3.11/site-packages/asyncpg/connection.py", line 1385, in set_type_codec
    typeinfo = await self._introspect_type(typename, schema)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/sriharithyagarajan/Documents/GitHub-Projects/cocoindex/.venv/lib/python3.11/site-packages/asyncpg/connection.py", line 562, in _introspect_type
    raise ValueError(
ValueError: unknown type: public.vector. Help me do stuff.

---

I ran those commands, now I'm getting a short error: (cocoindex) sriharithyagarajan@Sriharis-MacBook-Pro entire_session_search % psql "postgres://cocoindex:cocoindex@localhost/cocoindex" -c "CREATE EXTENSION IF NOT
   EXISTS vector;"
CREATE EXTENSION
(cocoindex) sriharithyagarajan@Sriharis-MacBook-Pro entire_session_search % cocoindex u
pdate main.py 
Traceback (most recent call last):
  File "/Users/sriharithyagarajan/Documents/GitHub-Projects/cocoindex/.venv/bin/cocoindex", line 4, in <module>
    from cocoindex.cli import cli
ModuleNotFoundError: No module named 'cocoindex'. Help resolve this.

---

Honestly, I just enabled entire for this directory (if needed, checkout how entire works using it's CLI --help) or you might already know enough from how it works based off @entire-cli-indexing-report.md and @../../Pitch-proposal.md Can oyu tell me how to move forward with populating entire stuff now? Like Iwant to test stuff and see good outputs. NOw that we built the index, we need data so I can proceed with the Search you sessions part of the README.

---

Ok, before asking you to commit files: I got the following thing I want yuo to do: my fork right now is sort of screwed up in the sense that, it seems to say it's 3 commits ahead of cocoindex main and I have the option to open a PR but when I do so, there's literally no files to add (0 additions or deletions). I need to get my remote synced up properly first. Also, then I want you to absolutely check each and every file before you commit it (if that file change is really necessary for the example we're trying to push in the v1 beanch PR). Like I still have a doubt re: @.claude/settings.json (why was stuff modified there)? Anything that we can revisit in the files of the examples folder  and subfolder we created for this? To make it more personalized, appear unique? Anything we missed updating (after having successfully run the commands). Take your time. Come up with a good plan. I do not wany you to commit messages that sound AI generated btw. Keep it very short and relevnt. Reefer to my localy Claude.md files on my writings tyle and preferences. I use backticks for the papropriate file edits. Keep it short (do not care about grammar). Also, I do not want the entire branch to be cmomitted btw (is that necessary)? NOw go!

---

[Request interrupted by user for tool use]